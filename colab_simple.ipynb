{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# 🎯 SEMA VOC Analysis\n\nKorean Voice of Customer sentiment analysis for Google Colab.\n\n## Steps:\n1. Run setup cell\n2. Process files\n3. Download results",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Setup",
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "print(\"🔧 Setting up environment...\")\n\n# Install system dependencies\n!apt-get update -qq && apt-get install -y openjdk-8-jdk -qq\n\n# Set Java environment\nimport os\nos.environ['JAVA_HOME'] = '/usr/lib/jvm/java-8-openjdk-amd64'\n\n# Install packages\n!pip install -q \"huggingface_hub>=0.16.0\" \"torch>=2.0.0\" \"transformers>=4.30.0,<5.0.0\" \"torchmetrics>=0.11.0\" \"lightning>=2.0.0\" konlpy\n\n# Setup repository\n!git clone -q https://github.com/shc443/sema_inf.git\n%cd sema_inf\n!pip install -q -e .\n\nprint(\"✅ Setup complete!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Process Files",
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "from colab_cli import SemaColabCLI\n\nprint(\"🚀 Initializing SEMA...\")\nsema = SemaColabCLI()\n\nprint(\"📤 Upload Excel files (with VOC1/VOC2 columns):\")\nuploaded_files = sema.upload_files()\n\nif uploaded_files:\n    print(f\"🔄 Processing {len(uploaded_files)} files...\")\n    success_count = sema.process_all_files()\n    \n    if success_count > 0:\n        print(f\"🎉 Processed {success_count} files!\")\n        sema.download_results()\n        print(\"✅ Complete! Check downloads.\")\n    else:\n        print(\"❌ Processing failed.\")\nelse:\n    print(\"❌ No files uploaded.\")"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "import os\nimport torch\n\ninput_files = [f for f in os.listdir('data/input') if f.endswith('.xlsx')]\noutput_files = [f for f in os.listdir('data/output') if f.endswith('.xlsx')]\n\nprint(f\"📁 Input: {len(input_files)} files\")\nprint(f\"📁 Output: {len(output_files)} files\")\nprint(f\"🖥️ GPU: {torch.cuda.is_available()}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Download Again",
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "sema.download_results()"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}